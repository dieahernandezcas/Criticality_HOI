{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script 3: High-Order Interactions Analysis (EEG)\n",
    "## Analyze high-order statistical interactions (cumulants of order 2, 3, and 4)\n",
    "## in EEG binary activity, with focus on activity during and outside of avalanches.\n",
    "## This notebook assumes the output from Scripts 1 and 2 is available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries\n",
    "Load libraries for data manipulation and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import moment, skew, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Data Path and Load Binary EEG and Avalanche Windows ---\n",
    "Ensure this path points to the 'eeg_binary.npy' file generated by the simulation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG data loaded successfully. Shape: (20000, 64)\n",
      "Samples inside avalanches: 16749\n",
      "Samples outside avalanches: 3251\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../Data/m_1.0_spont_0.0001/eeg_binary.npy\" # Use consistent spontaneous rate\n",
    "\n",
    "try:\n",
    "    eeg = np.load(data_path)\n",
    "    print(f\"EEG data loaded successfully. Shape: {eeg.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}.\")\n",
    "    print(\"Please ensure the simulation script has been run and the path is correct.\")\n",
    "    exit() # Exit if data is not found, as further analysis won't be possible\n",
    "\n",
    "n_time, n_channels = eeg.shape\n",
    "\n",
    "# Re-detect avalanches for consistency, similar to the previous script\n",
    "global_activity = np.any(eeg, axis=1).astype(int)\n",
    "transitions = np.diff(np.concatenate([[0], global_activity, [0]]))\n",
    "starts = np.where(transitions == 1)[0]\n",
    "ends = np.where(transitions == -1)[0]\n",
    "avalanches = [(start, end) for start, end in zip(starts, ends)]\n",
    "\n",
    "# Extract activity within avalanches\n",
    "# Ensure that in_aval is not empty before concatenating\n",
    "in_aval_segments = [eeg[start:end] for start, end in avalanches if end <= n_time and (end - start) > 0]\n",
    "if in_aval_segments:\n",
    "    in_aval = np.vstack(in_aval_segments)\n",
    "else:\n",
    "    in_aval = np.array([]) # Set as empty array if no segments\n",
    "    print(\"Warning: No 'in_aval' segments found. Cumulant analysis for this state will be skipped.\")\n",
    "\n",
    "# Extract activity outside avalanches (global silence periods)\n",
    "mask = np.ones(n_time, dtype=bool)\n",
    "for start, end in avalanches:\n",
    "    mask[start:end] = False # Mark time steps inside avalanches as False\n",
    "\n",
    "out_aval = eeg[mask]\n",
    "if out_aval.shape[0] == 0:\n",
    "    out_aval = np.array([]) # Set as empty array if no data\n",
    "    print(\"Warning: No 'out_aval' samples found (all time steps were active or within an avalanche). Cumulant analysis for this state will be skipped.\")\n",
    "\n",
    "\n",
    "print(f\"Samples inside avalanches: {in_aval.shape[0]}\")\n",
    "print(f\"Samples outside avalanches: {out_aval.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define High-Order Cumulant Functions ---\n",
    "These functions compute the generalized cumulants for multivariate data.\n",
    "For binary data, these are particularly interesting as they reveal deviations from independence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_second_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the second-order cumulant (covariance) for all unique pairs of channels.\n",
    "    Equivalent to covariance for mean-centered data.\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    # Iterate over unique pairs (i, j) where i < j\n",
    "    for i in range(n_channels):\n",
    "        for j in range(i, n_channels): # Include i=j for variance (diagonal)\n",
    "            if i == j: # Variance (diagonal elements)\n",
    "                cumulants[(i, j)] = np.var(X[:, i])\n",
    "            else: # Covariance (off-diagonal elements)\n",
    "                cumulants[(i, j)] = np.cov(X[:, i], X[:, j])[0, 1]\n",
    "    return cumulants\n",
    "\n",
    "def compute_third_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the third-order cumulant for all unique triplets of channels.\n",
    "    This captures triplet interactions and is related to skewness.\n",
    "    For mean-centered random variables x, y, z, it's E[xyz].\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    if n_channels < 3:\n",
    "        return cumulants # Cannot compute 3rd order cumulant for less than 3 channels\n",
    "\n",
    "    # Mean-center the data once for efficiency\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "\n",
    "    for comb in itertools.combinations(range(n_channels), 3):\n",
    "        i, j, k = comb\n",
    "        val = np.mean(X_centered[:, i] * X_centered[:, j] * X_centered[:, k])\n",
    "        cumulants[comb] = val\n",
    "    return cumulants\n",
    "\n",
    "def compute_fourth_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the fourth-order cumulant for all unique quadruplets of channels.\n",
    "    This captures quadruplet interactions and is related to kurtosis.\n",
    "    For mean-centered random variables x1, x2, x3, x4, it's E[x1x2x3x4] - E[x1x2]E[x3x4] - E[x1x3]E[x2x4] - E[x1x4]E[x2x3].\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    if n_channels < 4:\n",
    "        return cumulants # Cannot compute 4th order cumulant for less than 4 channels\n",
    "\n",
    "    # Mean-center the data once for efficiency\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "\n",
    "    for comb in itertools.combinations(range(n_channels), 4):\n",
    "        i, j, k, l = comb\n",
    "        x1 = X_centered[:, i]\n",
    "        x2 = X_centered[:, j]\n",
    "        x3 = X_centered[:, k]\n",
    "        x4 = X_centered[:, l]\n",
    "\n",
    "        term1 = np.mean(x1 * x2 * x3 * x4)\n",
    "        term2 = np.mean(x1 * x2) * np.mean(x3 * x4)\n",
    "        term3 = np.mean(x1 * x3) * np.mean(x2 * x4)\n",
    "        term4 = np.mean(x1 * x4) * np.mean(x2 * x3)\n",
    "\n",
    "        val = term1 - term2 - term3 - term4\n",
    "        cumulants[comb] = val\n",
    "    return cumulants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute Cumulants Inside and Outside Avalanches ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulants_in_aval_dict = {}\n",
    "cumulants_out_aval_dict = {}\n",
    "\n",
    "# Compute 2nd order cumulants (covariance)\n",
    "if in_aval.shape[0] > 1: # Need at least 2 samples for variance/covariance\n",
    "    cumulants_in_aval_dict[2] = compute_second_order_cumulant(in_aval)\n",
    "else:\n",
    "    print(\"Skipping 2nd order cumulants 'in_aval' due to insufficient data.\")\n",
    "if out_aval.shape[0] > 1:\n",
    "    cumulants_out_aval_dict[2] = compute_second_order_cumulant(out_aval)\n",
    "else:\n",
    "    print(\"Skipping 2nd order cumulants 'out_aval' due to insufficient data.\")\n",
    "\n",
    "\n",
    "# Compute 3rd order cumulants (skewness-related)\n",
    "if in_aval.shape[0] > 2 and n_channels >= 3: # Need at least 3 samples and 3 channels\n",
    "    cumulants_in_aval_dict[3] = compute_third_order_cumulant(in_aval)\n",
    "else:\n",
    "    print(\"Skipping 3rd order cumulants 'in_aval' due to insufficient data/channels.\")\n",
    "if out_aval.shape[0] > 2 and n_channels >= 3:\n",
    "    cumulants_out_aval_dict[3] = compute_third_order_cumulant(out_aval)\n",
    "else:\n",
    "    print(\"Skipping 3rd order cumulants 'out_aval' due to insufficient data/channels.\")\n",
    "\n",
    "# Compute 4th order cumulants (kurtosis-related)\n",
    "if in_aval.shape[0] > 3 and n_channels >= 4: # Need at least 4 samples and 4 channels\n",
    "    cumulants_in_aval_dict[4] = compute_fourth_order_cumulant(in_aval)\n",
    "else:\n",
    "    print(\"Skipping 4th order cumulants 'in_aval' due to insufficient data/channels.\")\n",
    "if out_aval.shape[0] > 3 and n_channels >= 4:\n",
    "    cumulants_out_aval_dict[4] = compute_fourth_order_cumulant(out_aval)\n",
    "else:\n",
    "    print(\"Skipping 4th order cumulants 'out_aval' due to insufficient data/channels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize Cumulant Magnitudes ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cumulants comparison plot saved to: ../Data/m_1.0_spont_0.0001/cumulants_comparison.png\n",
      "\n",
      "--- Summary of Cumulant Analysis ---\n",
      "\n",
      "Order 2 Cumulants:\n",
      "  Average value inside avalanches: 0.015051\n",
      "  Average value outside avalanches: 0.000000\n",
      "\n",
      "Order 3 Cumulants:\n",
      "  Average value inside avalanches: -0.012481\n",
      "  Average value outside avalanches: 0.000000\n",
      "  Non-zero values for order 3 suggest presence of high-order interactions and non-Gaussian dynamics.\n",
      "  Higher absolute cumulant values are observed *inside* avalanches, suggesting stronger high-order interactions during active periods.\n",
      "\n",
      "Order 4 Cumulants:\n",
      "  Average value inside avalanches: 0.010168\n",
      "  Average value outside avalanches: 0.000000\n",
      "  Non-zero values for order 4 suggest presence of high-order interactions and non-Gaussian dynamics.\n",
      "  Higher absolute cumulant values are observed *inside* avalanches, suggesting stronger high-order interactions during active periods.\n",
      "\n",
      "High-order interaction analysis complete.\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.dirname(data_path)\n",
    "os.makedirs(output_dir, exist_ok=True) # Ensure output directory exists\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=False) # No shared Y to allow different scales\n",
    "\n",
    "orders = [2, 3, 4]\n",
    "titles = [\"2nd Order Cumulants (Covariance)\", \"3rd Order Cumulants (Skewness-related)\", \"4th Order Cumulants (Kurtosis-related)\"]\n",
    "\n",
    "for i, order in enumerate(orders):\n",
    "    ax = axes[i]\n",
    "    cum_in_vals = np.array(list(cumulants_in_aval_dict.get(order, {}).values()))\n",
    "    cum_out_vals = np.array(list(cumulants_out_aval_dict.get(order, {}).values()))\n",
    "\n",
    "    # Plotting histograms of absolute cumulant values\n",
    "    if len(cum_in_vals) > 0:\n",
    "        ax.hist(np.abs(cum_in_vals), bins=50, density=True, alpha=0.6, label='Inside Avalanches', color='blue', histtype='stepfilled')\n",
    "    else:\n",
    "        print(f\"No data for plotting {order}th order cumulants 'in_aval'.\")\n",
    "\n",
    "    if len(cum_out_vals) > 0:\n",
    "        ax.hist(np.abs(cum_out_vals), bins=50, density=True, alpha=0.6, label='Outside Avalanches', color='red', histtype='stepfilled')\n",
    "    else:\n",
    "        print(f\"No data for plotting {order}th order cumulants 'out_aval'.\")\n",
    "\n",
    "    ax.set_title(titles[i], fontsize=14)\n",
    "    ax.set_xlabel(f'Absolute Cumulant Value (Order {order})', fontsize=12)\n",
    "    if i == 0: # Only set ylabel for the first subplot\n",
    "        ax.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.set_yscale('log') # Use log scale for y-axis to better see distributions\n",
    "\n",
    "plt.suptitle('Comparison of High-Order Cumulants: Inside vs. Outside Avalanches', fontsize=16, y=1.02)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjust layout to prevent title overlap\n",
    "cumulants_plot_path = os.path.join(output_dir, \"cumulants_comparison.png\")\n",
    "plt.savefig(cumulants_plot_path, dpi=300)\n",
    "plt.close()\n",
    "print(f\"\\nCumulants comparison plot saved to: {cumulants_plot_path}\")\n",
    "\n",
    "# --- 5. Qualitative Summary of Results ---\n",
    "print(\"\\n--- Summary of Cumulant Analysis ---\")\n",
    "for order in orders:\n",
    "    if cumulants_in_aval_dict.get(order) and cumulants_out_aval_dict.get(order):\n",
    "        mean_in = np.mean(list(cumulants_in_aval_dict[order].values()))\n",
    "        mean_out = np.mean(list(cumulants_out_aval_dict[order].values()))\n",
    "        print(f\"\\nOrder {order} Cumulants:\")\n",
    "        print(f\"  Average value inside avalanches: {mean_in:.6f}\")\n",
    "        print(f\"  Average value outside avalanches: {mean_out:.6f}\")\n",
    "        # Note: For binary data, cumulants might be small but non-zero.\n",
    "        # The key is their *relative* magnitude and distribution.\n",
    "        if order > 2: # For higher orders, non-zero values indicate non-Gaussianity and HOI\n",
    "            print(f\"  Non-zero values for order {order} suggest presence of high-order interactions and non-Gaussian dynamics.\")\n",
    "            if np.abs(mean_in) > np.abs(mean_out):\n",
    "                print(f\"  Higher absolute cumulant values are observed *inside* avalanches, suggesting stronger high-order interactions during active periods.\")\n",
    "            else:\n",
    "                print(f\"  Higher absolute cumulant values are observed *outside* avalanches, suggesting different underlying dynamics during silent periods.\")\n",
    "\n",
    "    elif cumulants_in_aval_dict.get(order):\n",
    "        mean_in = np.mean(list(cumulants_in_aval_dict[order].values()))\n",
    "        print(f\"\\nOrder {order} Cumulants (only inside avalanches data available):\")\n",
    "        print(f\"  Average value inside avalanches: {mean_in:.6f}\")\n",
    "    elif cumulants_out_aval_aval_dict.get(order):\n",
    "        mean_out = np.mean(list(cumulants_out_aval_dict[order].values()))\n",
    "        print(f\"\\nOrder {order} Cumulants (only outside avalanches data available):\")\n",
    "        print(f\"  Average value outside avalanches: {mean_out:.6f}\")\n",
    "    else:\n",
    "        print(f\"\\nOrder {order} Cumulants: No sufficient data to compute for either state.\")\n",
    "\n",
    "\n",
    "print(\"\\nHigh-order interaction analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python_Colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
