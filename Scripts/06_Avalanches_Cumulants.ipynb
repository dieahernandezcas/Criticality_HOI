{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Cumulants and Their Application\n",
    "\n",
    "**Cumulants** are a set of statistical properties of a probability distribution that, like moments, describe the shape of the distribution. However, unlike moments, cumulants possess the property of additivity: the cumulant of a sum of independent random variables is the sum of their individual cumulants. This makes them ideal for revealing **nonlinear and high-order interactions** between variables.\n",
    "\n",
    "---\n",
    "\n",
    "### Mathematical Definition of Cumulants\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_N$ be a set of random variables representing activity from different channels.\n",
    "\n",
    "We define the **raw moments** as follows:\n",
    "* $m_i = E[X_i]$\n",
    "* $m_{ij} = E[X_i X_j]$\n",
    "* $m_{ijk} = E[X_i X_j X_k]$\n",
    "* And so on for higher orders, where $m_{i_1 i_2 \\dots i_k} = E[X_{i_1} X_{i_2} \\dots X_{i_k}]$.\n",
    "\n",
    "Now, the cumulants can be defined in terms of these raw moments:\n",
    "\n",
    "1.  **First Cumulant ($C_1$) - The Mean:**\n",
    "    $$C_1(X_i) = m_i$$\n",
    "    This is the **expected value** or **mean** of the variable.\n",
    "\n",
    "2.  **Second Cumulant ($C_2$) - The Covariance:**\n",
    "    $$C_2(X_i, X_j) = m_{ij} - m_i m_j$$\n",
    "    This is the **covariance** between $X_i$ and $X_j$. If $i=j$, it is the **variance** of $X_i$.\n",
    "\n",
    "3.  **Third Cumulant ($C_3$) - Related to Skewness:**\n",
    "    $$C_3(X_i, X_j, X_k) = m_{ijk} - m_i m_{jk} - m_j m_{ik} - m_k m_{ij} + 2 m_i m_j m_k$$\n",
    "    This captures the **asymmetry** and higher-order interactions among the triplet of variables.\n",
    "\n",
    "4.  **Fourth Cumulant ($C_4$) - Related to Kurtosis:**\n",
    "    $$C_4(X_i, X_j, X_k, X_l) = m_{ijkl} - (m_i m_{jkl} + m_j m_{ikl} + m_k m_{ijl} + m_l m_{ijk}) + (m_i m_j m_{kl} + m_i m_k m_{jl} + m_i m_l m_{jk} + m_j m_k m_{il} + m_j m_l m_{ik} + m_k m_l m_{ij}) - 6 m_i m_j m_k m_l$$\n",
    "    This captures genuine **fourth-order interactions** beyond what can be explained by lower-order moments, indicating non-Gaussianity.\n",
    "\n",
    "### Simplification for Mean-Centered Variables (in terms of Expected Values)\n",
    "\n",
    "In many practical applications, data is often **mean-centered** before computing higher-order statistics. A variable $\\tilde{X}_i = X_i - E[X_i]$ has a mean of zero ($E[\\tilde{X}_i] = 0$). When variables are mean-centered:\n",
    "\n",
    "* **All first-order expected values of the centered variables become zero ($E[\\tilde{X}_i] = 0$).**\n",
    "* This **simplifies significantly the formulas** for higher-order cumulants:\n",
    "\n",
    "1.  **First Cumulant ($C_1$) of centered variables:**\n",
    "    $$C_1(\\tilde{X}_i) = E[\\tilde{X}_i] = 0$$\n",
    "\n",
    "2.  **Second Cumulant ($C_2$) of centered variables:**\n",
    "    $$C_2(\\tilde{X}_i, \\tilde{X}_j) = E[\\tilde{X}_i \\tilde{X}_j]$$\n",
    "\n",
    "3.  **Third Cumulant ($C_3$) of centered variables:**\n",
    "    $$C_3(\\tilde{X}_i, \\tilde{X}_j, \\tilde{X}_k) = E[\\tilde{X}_i \\tilde{X}_j \\tilde{X}_k]$$\n",
    "\n",
    "4.  **Fourth Cumulant ($C_4$) of centered variables:**\n",
    "    $$C_4(\\tilde{X}_i, \\tilde{X}_j, \\tilde{X}_k, \\tilde{X}_l) = E[\\tilde{X}_i \\tilde{X}_j \\tilde{X}_k \\tilde{X}_l] - (E[\\tilde{X}_i \\tilde{X}_j]E[\\tilde{X}_k \\tilde{X}_l] + E[\\tilde{X}_i \\tilde{X}_k]E[\\tilde{X}_j \\tilde{X}_l] + E[\\tilde{X}_i \\tilde{X}_l]E[\\tilde{X}_j \\tilde{X}_k])$$\n",
    "\n",
    "---\n",
    "\n",
    "## Application of Cumulants\n",
    "\n",
    "The script is designed to precisely calculate these cumulants (orders 2, 3, and 4) for **binarized EEG activity data** from synthetic patients, with a crucial focus on comparing interactions **during avalanches** versus **outside of them**.\n",
    "\n",
    "The script works as follows:\n",
    "\n",
    "1.  **Per-Patient Data Loading:** It iterates through each patient. For each patient, it loads the previously segmented binarized activity data (for \"during avalanches\" in `binarized_during_avalanches` and \"outside avalanches\" in `binarized_outside_avalanches`) from the `../results/avalanches/` folder.\n",
    "\n",
    "2.  **Generalized Cumulant Calculation:** It uses dedicated functions (`compute_second_order_cumulant`, `compute_third_order_cumulant`, `compute_fourth_order_cumulant`) that implement the mathematical definitions mentioned above. These functions handle the combinations of channels to compute covariance, triplet, and quadruplet interactions, respectively, on the binarized data.\n",
    "\n",
    "3.  **Segmented Analysis:** Cumulants are calculated separately for time periods **inside avalanches** and for periods **outside avalanches**. This allows for a direct comparison to understand how high-order interactions change based on the network's activity state.\n",
    "\n",
    "4.  **Result Saving:** The calculated cumulants for each patient are stored in individual `.pkl` files (e.g., `patient_00_cumulants.pkl`) within the `../results/cumulants/` folder. This output format facilitates later analysis and aggregation of results at a group level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory '../results/cumulants' ensured.\n",
      "Starting cumulant calculation for 20 patients...\n",
      "\n",
      "--- Processing Patient 00 for Cumulants ---\n",
      "  Samples within avalanches: 80\n",
      "  Samples outside avalanches: 80\n",
      "  Calculating order 2 cumulants...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 144\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_aval\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_samples_needed \u001b[38;5;129;01mand\u001b[39;00m n_channels \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m order:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m         cumulants_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_aval\u001b[39m\u001b[38;5;124m'\u001b[39m][order] \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_second_order_cumulant\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_aval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m order \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    146\u001b[0m         cumulants_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_aval\u001b[39m\u001b[38;5;124m'\u001b[39m][order] \u001b[38;5;241m=\u001b[39m compute_third_order_cumulant(in_aval)\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mcompute_second_order_cumulant\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     28\u001b[0m             cumulants[(i, j)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(X[:, i])\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Covariance (off-diagonal elements)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m             cumulants[(i, j)] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cumulants\n",
      "File \u001b[0;32m~/Documents/Virtual_Enviroment/Python_Colab/lib/python3.10/site-packages/numpy/lib/function_base.py:2748\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2746\u001b[0m     X_T \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m*\u001b[39mw)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m   2747\u001b[0m c \u001b[38;5;241m=\u001b[39m dot(X, X_T\u001b[38;5;241m.\u001b[39mconj())\n\u001b[0;32m-> 2748\u001b[0m c \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfact\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "# --- Configuration ---\n",
    "# Directory where the avalanche-segmented data for the patients is located.\n",
    "# This is the result of the previous script.\n",
    "INPUT_AVALANCHE_DIR = \"../results/avalanches\"\n",
    "# Directory where the cumulants calculated for each patient will be saved.\n",
    "OUTPUT_CUMULANTS_DIR = \"../results/cumulants\"\n",
    "# Total number of patients to process; must match the previous data generation.\n",
    "NUM_PATIENTS = 20\n",
    "\n",
    "# --- Helper Function: Second-Order Cumulant Calculation ---\n",
    "def compute_second_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the second-order cumulant (covariance) for all unique pairs of channels.\n",
    "    It is equivalent to covariance for mean-centered data.\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    # Iterate over unique pairs (i, j) where i < j\n",
    "    for i in range(n_channels):\n",
    "        for j in range(i, n_channels): # Include i=j for variance (diagonal elements)\n",
    "            if i == j: # Variance (diagonal elements)\n",
    "                cumulants[(i, j)] = np.var(X[:, i])\n",
    "            else: # Covariance (off-diagonal elements)\n",
    "                cumulants[(i, j)] = np.cov(X[:, i], X[:, j])[0, 1]\n",
    "    return cumulants\n",
    "\n",
    "# --- Helper Function: Third-Order Cumulant Calculation ---\n",
    "def compute_third_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the third-order cumulant for all unique triplets of channels.\n",
    "    This captures triplet interactions and is related to skewness.\n",
    "    For mean-centered random variables x, y, z, it is E[xyz].\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    if n_channels < 3:\n",
    "        return cumulants # Cannot compute 3rd-order cumulant for fewer than 3 channels\n",
    "\n",
    "    # Center data to the mean once for better efficiency\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "\n",
    "    for comb in itertools.combinations(range(n_channels), 3):\n",
    "        i, j, k = comb\n",
    "        val = np.mean(X_centered[:, i] * X_centered[:, j] * X_centered[:, k])\n",
    "        cumulants[comb] = val\n",
    "    return cumulants\n",
    "\n",
    "# --- Helper Function: Fourth-Order Cumulant Calculation ---\n",
    "def compute_fourth_order_cumulant(X):\n",
    "    \"\"\"\n",
    "    Computes the fourth-order cumulant for all unique quadruplets of channels.\n",
    "    This captures quadruplet interactions and is related to kurtosis.\n",
    "    For mean-centered random variables x1, x2, x3, x4, it is\n",
    "    E[x1x2x3x4] - E[x1x2]E[x3x4] - E[x1x3]E[x2x4] - E[x1x4]E[x2x3].\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    cumulants = defaultdict(float)\n",
    "    if n_channels < 4:\n",
    "        return cumulants # Cannot compute 4th-order cumulant for fewer than 4 channels\n",
    "\n",
    "    # Center data to the mean once for better efficiency\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "\n",
    "    for comb in itertools.combinations(range(n_channels), 4):\n",
    "        i, j, k, l = comb\n",
    "        x1 = X_centered[:, i]\n",
    "        x2 = X_centered[:, j]\n",
    "        x3 = X_centered[:, k]\n",
    "        x4 = X_centered[:, l]\n",
    "\n",
    "        term1 = np.mean(x1 * x2 * x3 * x4)\n",
    "        term2 = np.mean(x1 * x2) * np.mean(x3 * x4)\n",
    "        term3 = np.mean(x1 * x3) * np.mean(x2 * x4)\n",
    "        term4 = np.mean(x1 * x4) * np.mean(x2 * x3)\n",
    "\n",
    "        val = term1 - term2 - term3 - term4\n",
    "        cumulants[comb] = val\n",
    "    return cumulants\n",
    "\n",
    "# --- Main Script to Calculate Cumulants by Avalanche State for Each Patient ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure the cumulants results directory exists.\n",
    "    os.makedirs(OUTPUT_CUMULANTS_DIR, exist_ok=True)\n",
    "    print(f\"Output directory '{OUTPUT_CUMULANTS_DIR}' ensured.\")\n",
    "\n",
    "    print(f\"Starting cumulant calculation for {NUM_PATIENTS} patients...\")\n",
    "\n",
    "    # Iterate over each patient.\n",
    "    for patient_idx in range(NUM_PATIENTS):\n",
    "        # Build the filename for the current patient's pre-segmented avalanche data.\n",
    "        patient_avalanche_filename = os.path.join(INPUT_AVALANCHE_DIR, f\"patient_{patient_idx:02d}_avalanches.pkl\")\n",
    "\n",
    "        # Check if the segmented data file exists. If not, warn and skip this patient.\n",
    "        if not os.path.exists(patient_avalanche_filename):\n",
    "            print(f\"Warning: Avalanche segmented data not found for patient {patient_idx:02d} in {patient_avalanche_filename}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n--- Processing Patient {patient_idx:02d} for Cumulants ---\")\n",
    "        \n",
    "        with open(patient_avalanche_filename, 'rb') as f:\n",
    "            patient_data = pickle.load(f)\n",
    "        \n",
    "        in_aval = patient_data['binarized_during_avalanches']\n",
    "        out_aval = patient_data['binarized_outside_avalanches']\n",
    "        \n",
    "        # --- ADJUSTED LINE HERE ---\n",
    "        # Get the number of channels directly from the shape of the binarized data.\n",
    "        # This is more robust since 'n_channels' may not always be present in 'original_patient_params'.\n",
    "        # We assume that 'in_aval' (or 'out_aval' as a fallback) will always have the correct number of channels.\n",
    "        if in_aval.shape[1] > 0:\n",
    "            n_channels = in_aval.shape[1]\n",
    "        elif out_aval.shape[1] > 0:\n",
    "            n_channels = out_aval.shape[1]\n",
    "        else: # If both are empty in channel dimension, we cannot determine n_channels.\n",
    "            print(f\"Error: Could not determine the number of channels for patient {patient_idx:02d}. Both 'in_aval' and 'out_aval' are empty in channel dimensions.\")\n",
    "            continue # Skip this patient\n",
    "\n",
    "        print(f\"  Samples within avalanches: {in_aval.shape[0]}\")\n",
    "        print(f\"  Samples outside avalanches: {out_aval.shape[0]}\")\n",
    "\n",
    "        # Dictionary to store the cumulant results for the current patient.\n",
    "        cumulants_results = {\n",
    "            'in_aval': defaultdict(dict), # To store cumulants 'within avalanches'\n",
    "            'out_aval': defaultdict(dict) # To store cumulants 'outside avalanches'\n",
    "        }\n",
    "\n",
    "        # List of cumulant orders to compute.\n",
    "        orders_to_compute = [2, 3] #, 4]\n",
    "        \n",
    "        for order in orders_to_compute:\n",
    "            print(f\"  Calculating order {order} cumulants...\")\n",
    "            \n",
    "            # --- Compute for 'Within Avalanches' ---\n",
    "            # A minimum of 'order + 1' samples and 'order' channels is needed to compute an order 'order' cumulant.\n",
    "            min_samples_needed = order + 1\n",
    "            if in_aval.shape[0] >= min_samples_needed and n_channels >= order:\n",
    "                if order == 2:\n",
    "                    cumulants_results['in_aval'][order] = compute_second_order_cumulant(in_aval)\n",
    "                elif order == 3:\n",
    "                    cumulants_results['in_aval'][order] = compute_third_order_cumulant(in_aval)\n",
    "                elif order == 4:\n",
    "                    cumulants_results['in_aval'][order] = compute_fourth_order_cumulant(in_aval)\n",
    "                print(f\"    Order {order} 'in_aval' cumulants calculated for {len(cumulants_results['in_aval'][order])} combinations.\")\n",
    "            else:\n",
    "                print(f\"    Skipping order {order} 'in_aval' cumulants due to insufficient data (samples: {in_aval.shape[0]}, channels: {n_channels}). At least {min_samples_needed} samples and {order} channels are required.\")\n",
    "                \n",
    "            # --- Compute for 'Outside Avalanches' ---\n",
    "            if out_aval.shape[0] >= min_samples_needed and n_channels >= order:\n",
    "                if order == 2:\n",
    "                    cumulants_results['out_aval'][order] = compute_second_order_cumulant(out_aval)\n",
    "                elif order == 3:\n",
    "                    cumulants_results['out_aval'][order] = compute_third_order_cumulant(out_aval)\n",
    "                elif order == 4:\n",
    "                    cumulants_results['out_aval'][order] = compute_fourth_order_cumulant(out_aval)\n",
    "                print(f\"    Order {order} 'out_aval' cumulants calculated for {len(cumulants_results['out_aval'][order])} combinations.\")\n",
    "            else:\n",
    "                print(f\"    Skipping order {order} 'out_aval' cumulants due to insufficient data (samples: {out_aval.shape[0]}, channels: {n_channels}). At least {min_samples_needed} samples and {order} channels are required.\")\n",
    "\n",
    "        # Save the cumulants calculated for the current patient.\n",
    "        output_filename = os.path.join(OUTPUT_CUMULANTS_DIR, f\"patient_{patient_idx:02d}_cumulants.pkl\")\n",
    "        with open(output_filename, 'wb') as f:\n",
    "            pickle.dump(cumulants_results, f)\n",
    "            \n",
    "        print(f\"  Cumulant results for patient {patient_idx:02d} saved to '{output_filename}'\")\n",
    "\n",
    "    print(\"\\nAll patients have been successfully processed for cumulant calculation.\")\n",
    "    print(f\"Results are located in '{OUTPUT_CUMULANTS_DIR}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python_Colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
